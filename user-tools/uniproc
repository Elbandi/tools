#!/usr/bin/env perl

=pod

=head1 NAME

uniproc - Universal data processing tool

=head1 SYNOPSIS

uniproc [I<OPTIONS>] I<INPUTFILE> I<COMMAND> [I<ARGS>]

=head1 DESCRIPTION

Take each line from I<INPUTFILE> as B<DATA>,
pass each piece of B<DATA> to I<COMMAND> as the last argument,
then record the exit status.
Can be well parallelized.

Use a wrapper command/script for I<COMMAND> if you want either of these:

=over 4

=item save I<COMMAND>'s output as well. By default it goes to STDOUT.

=item pass B<DATA> on the STDIN or in environment variable instead of command argument.

=back

Maybe interrupted, then re-run to process the remaining data
or to re-try the failed ones.

May append new lines to I<INPUTFILE> between executions,
but not edit or reorder old ones, otherwise results get confused.

=head1 OPTIONS

=over 4

=item --retry

Process those data which were previously failed.

=back

=head1 FILES

It maintains I<INPUTFILE>.uniproc file
by writing the processing status of each lines of input data in it line-by-line.
Processing status is either:

=over 4

=item all spaces

processing not yet started

=item periods

in progress

=item digits (possibly padded by spaces)

result status (exit code)

=item exclamation mark (C<!>) followed by hexadecimal digits

termination signal (I<COMMAND> teminated abnormally)

=item EOF (ie. fewer lines than input data)

processing not yet started

=back

I<INPUTFILE>.uniproc is locked while read/write to ensure consistency.
I<INPUTFILE>.uniproc.B<NUM> are the name of the files which hold the lock for the currently in-progress processes,
where B<NUM> is the line number of the corresponding piece of data in I<INPUTFILE>.
A lock is held on each of these I<INPUTFILE>.proc.B<NUM> files by the respective instance of I<COMMAND>
to detect if the processing is still going or the process crashed.

=cut


use Fcntl qw/:flock :seek/;
use Data::Dumper;
use Getopt::Long qw/:config no_ignore_case no_bundling no_getopt_compat no_auto_abbrev require_order/;
use IPC::Run qw/run/;
use POSIX;
use Pod::Usage;

$OptRetry = 0;

GetOptions(
	'retry' => \$OptRetry,
	'help' => sub { pod2usage(-exitval=>0, -verbose=>99); },
) or pod2usage(-exitval=>2, -verbose=>99);

pod2usage(-exitval=>2, -verbose=>99) unless scalar @ARGV >= 2;


sub debug_msg
{
	#warn @_;
}

sub deriv_processing_status
{
	my $child_status = shift;
	my $status = sprintf '%3d', WEXITSTATUS($child_status);
	$status = sprintf '!%02x', WTERMSIG($child_status) if WIFSIGNALED($child_status);
	return $status;
}

sub fopen
{
	my $path = shift;
	my $opts = shift;  # supported opts: rw, no_create, lock
	my $mode = '<';  # default mode is read-only, no-create
	if($opts->{'rw'})
	{
		if(not $opts->{'no_create'})
		{
			open my $fh, '>>', $path or die "$0: $path: $!\n";
			close $fh;
		}
		$mode = '+<';
	}
	
	open my $fh, $mode, $path or die "$0: $path: $!\n";
	seek $fh, 0, SEEK_SET or die "$0: seek: $path: $!\n";
	if($opts->{'lock'})
	{
		flock $fh, LOCK_EX or die "$0: flock: $path: $!\n";
	}
	return $fh
}

sub extend_resultsfile
{
	my $fname = $ResultsFile;
	my $fh = shift;
	my $extended_size = shift;
	
	seek $fh, 0, SEEK_END;
	my $size = tell $fh;
	my $endpos_last_complete_record = int($size / $ResultsRecordLength) * $ResultsRecordLength;
	my $records_to_append = ($extended_size - $endpos_last_complete_record) / $ResultsRecordLength;
	debug_msg "go to offset $endpos_last_complete_record to extend by $records_to_append records\n";
	seek $fh, $size, SEEK_SET;
	# fill up with empty status records
	print {$Results_fh} "   \n" x $records_to_append or die "$0: write: $fname: $!\n";
}

sub record_status
{
	my $linenum = shift;
	my $status = shift;
	die "$0: size mismatch: length(\"$status\") != $ResultsRecordLength - 1\n" if length($status) != $ResultsRecordLength - 1;
	
	my $offset = $linenum * $ResultsRecordLength;
	debug_msg "go to offset $offset to record data # $linenum 's status \"$status\"\n";
	seek $Results_fh, $offset, SEEK_SET;
	if(eof $Results_fh)
	{
		debug_msg "eof\n";
		# results file is not big enough, let's extend
		extend_resultsfile($Results_fh, $offset);
		seek $Results_fh, $offset, SEEK_SET;
	}
	print {$Results_fh} "$status\n" or die "$0: write: $ResultsFile: $!\n";
}

sub input_data
{
	# TODO use index file, if exists, to seek in.
	
	my $asked_line = shift;
	my $fh = fopen $InputFile, {no_create=>1,};
	my $linenum = 0;
	my $data = undef;
	while(my $line = <$fh>)
	{
		if($linenum == $asked_line)
		{
			$data = $line;
			chomp $data;
			last;
		}
		$linenum++;
	}
	close $fh;
	return $data;
}

sub count_input_records
{
	# TODO use index file, if exists.
	
	my $fh = fopen $InputFile, {no_create=>1,};
	my $linenum = 0;
	$linenum++ while scalar <$fh>;
	close $fh;
	return $linenum;
}

sub processing_lockfile_name
{
	my $processing_number = shift;
	return "$InputFile.uniproc.$processing_number";
}

sub still_in_progress
{
	my $processing_number = shift;
	my $lockfile = processing_lockfile_name($processing_number);
	open my $fh, '<', $lockfile or return 0;
	my $lock_ok = flock $fh, LOCK_EX|LOCK_NB;
	close $fh;
	return not $lock_ok;
}

sub get_next_data_number
{
	debug_msg "go to offset ".($FirstUnprocessed*$ResultsRecordLength)." to read status of record # $FirstUnprocessed\n";
	seek $Results_fh, $FirstUnprocessed*$ResultsRecordLength, SEEK_SET;
	
	my $record_num = $FirstUnprocessed;
	my $result;
	while(1)
	{
		my $nbytes = read $Results_fh, $result, $ResultsRecordLength;
		debug_msg "read only $nbytes bytes \"$result\" at record $record_num\n" if $nbytes < $ResultsRecordLength;
		last if $nbytes < $ResultsRecordLength;
		chomp $result;
		
		if($result eq '   ')
		{
			$FirstUnprocessed = $record_num;
			debug_msg "uninitialized $record_num\n";
			return $record_num;
		}
		if($result eq '...')
		{
			# check if still locked
			if(not still_in_progress($record_num))
			{
				debug_msg "crashed $record_num\n";
				return $record_num;
			}
			# TODO re-examine in-progress records sometime
		}
		
		$record_num++;
	}
	
	# check here if there are more input data than result records
	my $input_records = count_input_records();
	if($record_num < $input_records)
	{
		extend_resultsfile($Results_fh, $input_records * $ResultsRecordLength);
		$FirstUnprocessed = $record_num;
		debug_msg "new $record_num\n";
		return $record_num;
	}
	
	# no more input data
	debug_msg "no more input. input_records=$input_records\n";
	return undef;
}


($InputFile, $Command, @Args) = @ARGV;

$FirstUnprocessed = 0;
$ResultsRecordLength = 4;
$ResultsFile = "$InputFile.uniproc";
$Results_fh = undef;

while(1)
{
	$Results_fh = fopen $ResultsFile, {rw=>1, lock=>1};
	my $LineNum = get_next_data_number();
	last if not defined $LineNum;
	
	my $Data = input_data($LineNum);
	
	my $InprogressFile = processing_lockfile_name($LineNum);
	my $inprogress_fh = fopen $InprogressFile, {rw=>1, lock=>1};
	
	record_status($LineNum, '...');
	close $Results_fh;
	
	run [$Command, @Args, $Data];
	my $status = $?;
	
	$Results_fh = fopen $ResultsFile, {rw=>1, lock=>1};
	record_status($LineNum, deriv_processing_status($status));
	close $Results_fh;
	
	close $inprogress_fh;
	unlink $InprogressFile;
}
